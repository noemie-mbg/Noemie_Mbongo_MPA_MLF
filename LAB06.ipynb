{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNyUhI/o32RKEdqqaa8x+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noemie-mbg/Noemie_Mbongo_MPA_MLF/blob/main/LAB06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyNdorSD5Ttt",
        "outputId": "953cfaf1-4500-4558-df05-c369e6885bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 957ms/step - accuracy: 0.3938 - loss: 2.0213 - val_accuracy: 0.1826 - val_loss: 2.9209\n",
            "Epoch 2/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 949ms/step - accuracy: 0.6002 - loss: 1.1353 - val_accuracy: 0.6405 - val_loss: 1.0062\n",
            "Epoch 3/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 956ms/step - accuracy: 0.6758 - loss: 0.9134 - val_accuracy: 0.6590 - val_loss: 0.9849\n",
            "Epoch 4/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 946ms/step - accuracy: 0.7145 - loss: 0.8131 - val_accuracy: 0.7007 - val_loss: 0.8387\n",
            "Epoch 5/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 896ms/step - accuracy: 0.7425 - loss: 0.7234 - val_accuracy: 0.7235 - val_loss: 0.7941\n",
            "Epoch 6/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 965ms/step - accuracy: 0.7672 - loss: 0.6615 - val_accuracy: 0.7523 - val_loss: 0.7243\n",
            "Epoch 7/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 948ms/step - accuracy: 0.7847 - loss: 0.6082 - val_accuracy: 0.7643 - val_loss: 0.6852\n",
            "Epoch 8/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 950ms/step - accuracy: 0.8023 - loss: 0.5506 - val_accuracy: 0.7372 - val_loss: 0.7626\n",
            "Epoch 9/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 942ms/step - accuracy: 0.8217 - loss: 0.5020 - val_accuracy: 0.7750 - val_loss: 0.6755\n",
            "Epoch 10/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 940ms/step - accuracy: 0.8351 - loss: 0.4670 - val_accuracy: 0.7833 - val_loss: 0.6751\n",
            "Epoch 11/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 963ms/step - accuracy: 0.8453 - loss: 0.4299 - val_accuracy: 0.7816 - val_loss: 0.6792\n",
            "Epoch 12/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 939ms/step - accuracy: 0.8650 - loss: 0.3891 - val_accuracy: 0.7965 - val_loss: 0.6297\n",
            "Epoch 13/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 926ms/step - accuracy: 0.8656 - loss: 0.3719 - val_accuracy: 0.7859 - val_loss: 0.6715\n",
            "Epoch 14/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 927ms/step - accuracy: 0.8775 - loss: 0.3402 - val_accuracy: 0.7856 - val_loss: 0.6723\n",
            "Epoch 15/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 931ms/step - accuracy: 0.8929 - loss: 0.3030 - val_accuracy: 0.8053 - val_loss: 0.6374\n",
            "Epoch 16/30\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 931ms/step - accuracy: 0.8924 - loss: 0.2988 - val_accuracy: 0.8065 - val_loss: 0.6250\n",
            "Epoch 17/30\n",
            "\u001b[1m 14/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:34\u001b[0m 916ms/step - accuracy: 0.8978 - loss: 0.2874"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "labels = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "          5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
        "\n",
        "# Image normalization\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "def display_random_images(x_data: np.array, y_data: np.array, count: int = 10) -> None:\n",
        "    \"\"\"Affiche un ensemble d'images aléatoires avec leurs étiquettes.\"\"\"\n",
        "    selected_ind = np.random.choice(len(x_data), count)\n",
        "    selected_img = x_data[selected_ind]\n",
        "    selected_labels = [labels[np.argmax(y_data[i])] for i in selected_ind]\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(count):\n",
        "        plt.subplot(1, count, i + 1)\n",
        "        plt.imshow(selected_img[i])\n",
        "        plt.title(selected_labels[i], fontsize=10)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Enhanced CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Optimization\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Model drive\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print(f'Test accuracy: {score[1]*100:.2f}%')\n",
        "\n",
        "# Performance display\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Évolution de la perte\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Évolution de l'accuracy\")\n",
        "plt.show()\n",
        "\n",
        "def show_the_best_predictions(model, x_test: np.array, y_test: np.array, n_of_pred: int = 10) -> None:\n",
        "    \"\"\"Affiche les meilleures prédictions avec la confiance du modèle.\"\"\"\n",
        "    predictions = model.predict(x_test)\n",
        "    predictions_ind = np.argmax(predictions, axis=1)\n",
        "    y_test_ind = np.argmax(y_test, axis=1)\n",
        "    correct_indices = np.where(predictions_ind == y_test_ind)[0]\n",
        "\n",
        "    if len(correct_indices) == 0:\n",
        "        print(\"Aucune prédiction correcte trouvée.\")\n",
        "        return\n",
        "\n",
        "    confidences = predictions[correct_indices, y_test_ind[correct_indices]]\n",
        "    sorted_ind = np.argsort(confidences)[::-1][:n_of_pred]\n",
        "    selected_images = x_test[correct_indices][sorted_ind]\n",
        "    selected_labels = y_test_ind[correct_indices][sorted_ind]\n",
        "    selected_confidences = confidences[sorted_ind]\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(len(sorted_ind)):\n",
        "        plt.subplot(1, n_of_pred, i + 1)\n",
        "        plt.imshow(selected_images[i])\n",
        "        plt.title(f\"{labels[selected_labels[i]]}:\\n{selected_confidences[i]*100:.2f}%\", fontsize=10)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display\n",
        "show_the_best_predictions(model, X_test, y_test)"
      ]
    }
  ]
}